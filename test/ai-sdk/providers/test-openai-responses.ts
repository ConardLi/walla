#!/usr/bin/env node
/**
 * OpenAI Responses æµ‹è¯•è„šæœ¬
 *
 * æµ‹è¯•ä½¿ç”¨ OpenAI Responses
 * - generateText: æ–‡æœ¬ç”Ÿæˆ
 * - streamText: æµå¼æ–‡æœ¬ç”Ÿæˆ
 */

import { createOpenAI } from "@ai-sdk/openai";
import { generateText, streamText } from "ai";
import { config, checkEnvVar } from "../utils/config";
import {
  logSection,
  logSuccess,
  logError,
  logInfo,
  logResponse,
} from "../utils/logger";

async function testBasicGeneration(provider: ReturnType<typeof createOpenAI>) {
  logSection("æµ‹è¯• 1: åŸºç¡€æ–‡æœ¬ç”Ÿæˆ");

  try {
    const { text, usage } = await generateText({
      model: provider.responses(config.openaiResponses.model),
      prompt: "ç”¨ä¸€å¥è¯ä»‹ç»äººå·¥æ™ºèƒ½",
    });

    logResponse("ç”Ÿæˆçš„æ–‡æœ¬", text);
    logInfo(`ä½¿ç”¨çš„ tokens: ${usage.totalTokens}`);
    logSuccess("åŸºç¡€æ–‡æœ¬ç”Ÿæˆæµ‹è¯•é€šè¿‡");
  } catch (error) {
    logError("åŸºç¡€æ–‡æœ¬ç”Ÿæˆæµ‹è¯•å¤±è´¥", error);
    throw error;
  }
}

async function testStreamGeneration(provider: ReturnType<typeof createOpenAI>) {
  logSection("æµ‹è¯• 2: æµå¼æ–‡æœ¬ç”Ÿæˆ");

  try {
    const { textStream } = await streamText({
      model: provider.responses(config.openaiResponses.model),
      prompt: "å†™ä¸€é¦–å…³äºç¼–ç¨‹çš„çŸ­è¯—",
    });

    process.stdout.write("ğŸ“ æµå¼è¾“å‡º: ");
    for await (const textPart of textStream) {
      process.stdout.write(textPart);
    }
    process.stdout.write("\n");

    logSuccess("æµå¼æ–‡æœ¬ç”Ÿæˆæµ‹è¯•é€šè¿‡");
  } catch (error) {
    logError("æµå¼æ–‡æœ¬ç”Ÿæˆæµ‹è¯•å¤±è´¥", error);
    throw error;
  }
}

async function main() {
  console.log("ğŸš€ å¼€å§‹æµ‹è¯• OpenAI Responses æ¥å£\n");

  const isValid = [
    checkEnvVar("OPENAI_COMPATIBLE_BASE_URL", config.openaiResponses.baseURL),
    checkEnvVar("OPENAI_COMPATIBLE_API_KEY", config.openaiResponses.apiKey),
  ].every(Boolean);

  if (!isValid) {
    logError(
      "è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® OPENAI_COMPATIBLE_BASE_URL å’Œ OPENAI_COMPATIBLE_API_KEY",
    );
    process.exit(1);
  }

  logInfo(`API åœ°å€: ${config.openaiResponses.baseURL}`);
  logInfo(`ä½¿ç”¨æ¨¡å‹: ${config.openaiResponses.model}\n`);

  const provider = createOpenAI({
    baseURL: config.openaiResponses.baseURL,
    apiKey: config.openaiResponses.apiKey,
    name: "openai-compatible",
  });

  try {
    await testBasicGeneration(provider);
    await testStreamGeneration(provider);

    console.log("\nâœ¨ æ ¸å¿ƒæµ‹è¯•é€šè¿‡ï¼");
  } catch (error) {
    console.log("\nğŸ’¥ æµ‹è¯•å¤±è´¥");
    process.exit(1);
  }
}

main();
